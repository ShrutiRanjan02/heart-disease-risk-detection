{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVfLV_pzjrCS",
    "outputId": "032c3bc3-9579-4554-8994-5943da404c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.6.0+cu124 | CUDA: False\n"
     ]
    }
   ],
   "source": [
    "import os, math, random, time, copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fceaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdamOptimizer:\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1, self.beta2 = betas\n",
    "        self.eps = eps\n",
    "        self.t = 0\n",
    "        self.m = [torch.zeros_like(p) for p in self.params]\n",
    "        self.v = [torch.zeros_like(p) for p in self.params]\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            g = p.grad\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (g * g)\n",
    "            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "            p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "F4QiFYFBkJRF",
    "outputId": "1d02f0fc-7f0c-4401-85bc-37bed2f5d488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (70000, 13)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 70000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28851,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          66728,\n          69098,\n          59185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2467,\n        \"min\": 10798,\n        \"max\": 23713,\n        \"num_unique_values\": 8076,\n        \"samples\": [\n          17317,\n          21437,\n          17627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 55,\n        \"max\": 250,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          125,\n          181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.39575667851056,\n        \"min\": 10.0,\n        \"max\": 200.0,\n        \"num_unique_values\": 287,\n        \"samples\": [\n          68.0,\n          88.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 154,\n        \"min\": -150,\n        \"max\": 16020,\n        \"num_unique_values\": 153,\n        \"samples\": [\n          11500,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 188,\n        \"min\": -70,\n        \"max\": 11000,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          810,\n          8044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cholesterol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gluc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoke\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alco\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"active\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cardio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1a8e482d-3bb5-4032-8db5-c3929cea9031\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a8e482d-3bb5-4032-8db5-c3929cea9031')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1a8e482d-3bb5-4032-8db5-c3929cea9031 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1a8e482d-3bb5-4032-8db5-c3929cea9031');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e04595cb-ca4b-45ea-96e0-036698813409\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e04595cb-ca4b-45ea-96e0-036698813409')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e04595cb-ca4b-45ea-96e0-036698813409 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#@title Load Data\n",
    "USE_UPLOAD = False #@param {type:\"boolean\"}\n",
    "DATA_PATH = \"cardio_train.csv\" #@param {type:\"string\"}\n",
    "\n",
    "if USE_UPLOAD:\n",
    "  try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    DATA_PATH = list(uploaded.keys())[0]\n",
    "  except Exception as e:\n",
    "    print(\"Colab upload not available in this environment, set USE_UPLOAD=False and adjust DATA_PATH.\")\n",
    "\n",
    "# Fallback for this environment (you can delete in Colab)\n",
    "fallback = \"/mnt/data/synthetic_heart_data.csv\"\n",
    "if not os.path.exists(DATA_PATH) and os.path.exists(fallback):\n",
    "  DATA_PATH = fallback\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnIfxCGjkSoN",
    "outputId": "de563602-bc35-4e9a-a2a6-5b470e954c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: cardio\n",
      "Numeric columns count: 6\n",
      "Categorical columns count: 6\n"
     ]
    }
   ],
   "source": [
    "# Candidate target column names to check\n",
    "candidate_targets = [\"target\", \"label\", \"class\", \"Outcome\", \"cardio\"]\n",
    "target_col = None\n",
    "for c in candidate_targets:\n",
    "    if c in df.columns:\n",
    "        target_col = c\n",
    "        break\n",
    "\n",
    "assert target_col is not None, f\"Could not find target col in {candidate_targets}. Edit this cell and set target_col.\"\n",
    "\n",
    "# Separate target and features\n",
    "y = df[target_col].astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Detect numeric vs categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "# Optionally treat low-cardinality integer columns as categorical\n",
    "INT_AS_CAT = True\n",
    "if INT_AS_CAT:\n",
    "    for c in numeric_cols.copy():\n",
    "        if str(X[c].dtype).startswith(\"int\") and X[c].nunique() <= 10:\n",
    "            categorical_cols.append(c)\n",
    "            numeric_cols.remove(c)\n",
    "\n",
    "print(\"Target column:\", target_col)\n",
    "print(\"Numeric columns count:\", len(numeric_cols))\n",
    "print(\"Categorical columns count:\", len(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y48GDHX1k82-"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Preprocessing utilities (no sklearn)\n",
    "def mode(series):\n",
    "  return series.value_counts(dropna=True).idxmax() if series.notna().any() else np.nan\n",
    "\n",
    "def impute_and_encode(df, numeric_cols, categorical_cols):\n",
    "  df = df.copy()\n",
    "  # Impute\n",
    "  for c in numeric_cols:\n",
    "    med = df[c].median()\n",
    "    df[c] = df[c].fillna(med)\n",
    "  for c in categorical_cols:\n",
    "    m = mode(df[c])\n",
    "    df[c] = df[c].fillna(m)\n",
    "\n",
    "  # One-hot encode categoricals\n",
    "  if categorical_cols:\n",
    "    df_cat = pd.get_dummies(df[categorical_cols].astype(\"category\"), dummy_na=False)\n",
    "  else:\n",
    "    df_cat = pd.DataFrame(index=df.index)\n",
    "\n",
    "  # Standardize numerics\n",
    "  df_num = df[numeric_cols].astype(float).copy()\n",
    "  mu = df_num.mean(axis=0)\n",
    "  sigma = df_num.std(axis=0).replace(0, 1.0)\n",
    "  df_num = (df_num - mu) / sigma\n",
    "\n",
    "  # Concatenate\n",
    "  X_proc = pd.concat([df_num, df_cat], axis=1)\n",
    "  meta = {\n",
    "      \"num_mean\": mu.to_dict(),\n",
    "      \"num_std\": sigma.to_dict(),\n",
    "      \"cat_levels\": {c: sorted(df[c].astype(\"category\").cat.categories.astype(str).tolist()) for c in categorical_cols},\n",
    "      \"ohe_cols\": list(df_cat.columns),\n",
    "      \"numeric_cols\": numeric_cols,\n",
    "      \"categorical_cols\": categorical_cols,\n",
    "  }\n",
    "  return X_proc.values.astype(np.float32), meta\n",
    "\n",
    "def transform_new(df_new, meta):\n",
    "  df_new = df_new.copy()\n",
    "  # Impute\n",
    "  for c in meta[\"numeric_cols\"]:\n",
    "    med = df_new[c].median()\n",
    "    df_new[c] = df_new[c].fillna(med)\n",
    "  for c in meta[\"categorical_cols\"]:\n",
    "    m = mode(df_new[c])\n",
    "    df_new[c] = df_new[c].fillna(m)\n",
    "\n",
    "  # One-hot to the same columns\n",
    "  if meta[\"categorical_cols\"]:\n",
    "    df_cat = pd.get_dummies(df_new[meta[\"categorical_cols\"]].astype(\"category\"), dummy_na=False)\n",
    "  else:\n",
    "    df_cat = pd.DataFrame(index=df_new.index)\n",
    "  # Align to training columns\n",
    "  for col in meta[\"ohe_cols\"]:\n",
    "    if col not in df_cat.columns:\n",
    "      df_cat[col] = 0\n",
    "  df_cat = df_cat[meta[\"ohe_cols\"]]\n",
    "\n",
    "  # Standardize numeric\n",
    "  df_num = df_new[meta[\"numeric_cols\"]].astype(float).copy()\n",
    "  mu = pd.Series(meta[\"num_mean\"])\n",
    "  sigma = pd.Series(meta[\"num_std\"]).replace(0, 1.0)\n",
    "  df_num = (df_num - mu) / sigma\n",
    "\n",
    "  X_proc = pd.concat([df_num, df_cat], axis=1)\n",
    "  return X_proc.values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXwwDvgNk_r3",
    "outputId": "8225d2e0-387d-4170-d93c-45ddad5f8f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 38023 / 70000 rows after IQR filtering.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title Outlier detection (IQR) — no sklearn\n",
    "APPLY_IQR = True #@param {type:\"boolean\"}\n",
    "\n",
    "X_raw = X.copy()\n",
    "mask_keep = np.ones(len(X_raw), dtype=bool)\n",
    "\n",
    "if APPLY_IQR:\n",
    "  num = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "  if num:\n",
    "    Q1 = X_raw[num].quantile(0.25)\n",
    "    Q3 = X_raw[num].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    m = ~((X_raw[num] < lower) | (X_raw[num] > upper)).any(axis=1)\n",
    "    mask_keep &= m.values\n",
    "\n",
    "X_clean = X_raw[mask_keep].reset_index(drop=True)\n",
    "y_clean = y[mask_keep]\n",
    "print(f\"Kept {X_clean.shape[0]} / {len(X)} rows after IQR filtering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XIDuRF1lDKk",
    "outputId": "0d741e39-e723-4fde-b2bc-2710856ffd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (38023, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title Fit preprocessing on cleaned data (no sklearn)\n",
    "X_ready, preprocess_meta = impute_and_encode(X_clean, numeric_cols, categorical_cols)\n",
    "print(\"Final feature matrix shape:\", X_ready.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1AOduIRlEQX",
    "outputId": "8dbfa0d3-f8bc-4c34-8568-9feb41a2fd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes — Train: (27472, 15) Val: (4848, 15) Test: (5703, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title Stratified train/val/test split (from scratch)\n",
    "def stratified_split(X, y, test_size=0.15, val_size=0.15, seed=42):\n",
    "  rng = np.random.default_rng(seed)\n",
    "  X = np.asarray(X)\n",
    "  y = np.asarray(y).astype(int)\n",
    "  classes = np.unique(y)\n",
    "  idx = np.arange(len(y))\n",
    "  train_idx, val_idx, test_idx = [], [], []\n",
    "  for c in classes:\n",
    "    c_idx = idx[y == c]\n",
    "    rng.shuffle(c_idx)\n",
    "    n = len(c_idx)\n",
    "    n_test = int(round(test_size * n))\n",
    "    n_val = int(round(val_size * (n - n_test)))\n",
    "    test_idx.extend(c_idx[:n_test])\n",
    "    val_idx.extend(c_idx[n_test:n_test+n_val])\n",
    "    train_idx.extend(c_idx[n_test+n_val:])\n",
    "  rng.shuffle(train_idx); rng.shuffle(val_idx); rng.shuffle(test_idx)\n",
    "  return (X[train_idx], y[train_idx],\n",
    "          X[val_idx], y[val_idx],\n",
    "          X[test_idx], y[test_idx])\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = stratified_split(X_ready, y_clean, test_size=0.15, val_size=0.15, seed=RANDOM_STATE)\n",
    "print(\"Shapes — Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A4ESYyklHm1"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@title Metrics from scratch\n",
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-np.clip(z, -50, 50)))\n",
    "\n",
    "def confusion_matrix_(y_true, y_pred):\n",
    "  y_true = y_true.astype(int)\n",
    "  y_pred = y_pred.astype(int)\n",
    "  tp = np.sum((y_true==1)&(y_pred==1))\n",
    "  tn = np.sum((y_true==0)&(y_pred==0))\n",
    "  fp = np.sum((y_true==0)&(y_pred==1))\n",
    "  fn = np.sum((y_true==1)&(y_pred==0))\n",
    "  return np.array([[tn, fp],[fn, tp]])\n",
    "\n",
    "def accuracy_score_(y_true, y_pred):\n",
    "  return float(np.mean(y_true.astype(int)==y_pred.astype(int)))\n",
    "\n",
    "def precision_score_(y_true, y_pred):\n",
    "  cm = confusion_matrix_(y_true, y_pred)\n",
    "  tp = cm[1,1]; fp = cm[0,1]\n",
    "  return float(tp / (tp+fp+1e-12))\n",
    "\n",
    "def recall_score_(y_true, y_pred):\n",
    "  cm = confusion_matrix_(y_true, y_pred)\n",
    "  tp = cm[1,1]; fn = cm[1,0]\n",
    "  return float(tp / (tp+fn+1e-12))\n",
    "\n",
    "def f1_score_(y_true, y_pred):\n",
    "  p = precision_score_(y_true, y_pred)\n",
    "  r = recall_score_(y_true, y_pred)\n",
    "  return float(2*p*r/(p+r+1e-12))\n",
    "\n",
    "def roc_auc_score_(y_true, y_score):\n",
    "  # Trapezoidal ROC AUC from scratch\n",
    "  y_true = y_true.astype(int)\n",
    "  order = np.argsort(-y_score)\n",
    "  y_true = y_true[order]\n",
    "  y_score = y_score[order]\n",
    "  P = np.sum(y_true==1); N = np.sum(y_true==0)\n",
    "  if P==0 or N==0: return float(\"nan\")\n",
    "  tps = 0; fps = 0\n",
    "  prev_score = None\n",
    "  auc = 0.0; prev_fpr = 0.0; prev_tpr = 0.0\n",
    "  for i in range(len(y_true)):\n",
    "    if prev_score is None or y_score[i] != prev_score:\n",
    "      # integrate\n",
    "      auc += (fps/N - prev_fpr) * (tps/P + prev_tpr) / 2.0\n",
    "      prev_fpr = fps/N\n",
    "      prev_tpr = tps/P\n",
    "      prev_score = y_score[i]\n",
    "    if y_true[i]==1: tps += 1\n",
    "    else: fps += 1\n",
    "  auc += (fps/N - prev_fpr) * (tps/P + prev_tpr) / 2.0\n",
    "  return float(auc)\n",
    "\n",
    "def average_precision_(y_true, y_score):\n",
    "  # PR AUC (Average Precision) from scratch\n",
    "  y_true = y_true.astype(int)\n",
    "  order = np.argsort(-y_score)\n",
    "  y_true = y_true[order]\n",
    "  P = np.sum(y_true==1)\n",
    "  if P==0: return float(\"nan\")\n",
    "  tp = 0; fp = 0; prev_recall = 0.0; ap = 0.0\n",
    "  for i in range(len(y_true)):\n",
    "    if y_true[i]==1: tp += 1\n",
    "    else: fp += 1\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / P\n",
    "    ap += precision * (recall - prev_recall)\n",
    "    prev_recall = recall\n",
    "  return float(ap)\n",
    "\n",
    "def evaluate_(y_true, y_prob, threshold=0.5, prefix=\"\"):\n",
    "  y_pred = (y_prob >= threshold).astype(int)\n",
    "  cm = confusion_matrix_(y_true, y_pred)\n",
    "  return {\n",
    "      f\"{prefix}Accuracy\": accuracy_score_(y_true, y_pred),\n",
    "      f\"{prefix}Precision\": precision_score_(y_true, y_pred),\n",
    "      f\"{prefix}Recall\": recall_score_(y_true, y_pred),\n",
    "      f\"{prefix}F1\": f1_score_(y_true, y_pred),\n",
    "      f\"{prefix}ROC_AUC\": roc_auc_score_(y_true, y_prob),\n",
    "      f\"{prefix}PR_AUC(AP)\": average_precision_(y_true, y_prob),\n",
    "      f\"{prefix}ConfusionMatrix\": cm.tolist()\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZN00D5ZSlKnD",
    "outputId": "8bfad674-ff9d-4656-ce4d-e41c103f03fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF (scratch) — Val Metrics\n",
      "{'RF/Val/Accuracy': 0.7421617161716172, 'RF/Val/Precision': 0.7568647029455813, 'RF/Val/Recall': 0.6652040368582709, 'RF/Val/F1': 0.7080803362909543, 'RF/Val/ROC_AUC': 0.8072970139976972, 'RF/Val/PR_AUC(AP)': 0.7770338680064336, 'RF/Val/ConfusionMatrix': [[2082, 487], [763, 1516]]}\n",
      "\n",
      "RF (scratch) — Test Metrics\n",
      "{'RF/Test/Accuracy': 0.7422409258285113, 'RF/Test/Precision': 0.7675651789659741, 'RF/Test/Recall': 0.6478925773964936, 'RF/Test/F1': 0.7026699029121246, 'RF/Test/ROC_AUC': 0.800472526352192, 'RF/Test/PR_AUC(AP)': 0.7770458029493591, 'RF/Test/ConfusionMatrix': [[2496, 526], [944, 1737]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title Random Forest (from scratch, NumPy)\n",
    "class DecisionTree:\n",
    "  def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1, mtry=None, random_state=42):\n",
    "    self.max_depth = max_depth\n",
    "    self.min_samples_split = int(min_samples_split)\n",
    "    self.min_samples_leaf = int(min_samples_leaf)\n",
    "    self.mtry = mtry\n",
    "    self.random_state = random_state\n",
    "    self.tree_ = None\n",
    "\n",
    "  @staticmethod\n",
    "  def gini(y, w=None):\n",
    "    if w is None:\n",
    "      w = np.ones_like(y, dtype=float)\n",
    "    wsum = np.sum(w);\n",
    "    if wsum==0: return 0.0\n",
    "    p1 = np.sum(w*(y==1))/wsum\n",
    "    p0 = 1.0 - p1\n",
    "    return 1.0 - p1*p1 - p0*p0\n",
    "\n",
    "  def best_split(self, X, y, w, feat_idxs):\n",
    "    n, d = X.shape\n",
    "    best = None\n",
    "    base_imp = self.gini(y, w)\n",
    "    for j in feat_idxs:\n",
    "      xj = X[:, j]\n",
    "      # sort unique thresholds\n",
    "      order = np.argsort(xj)\n",
    "      x_sorted = xj[order]\n",
    "      y_sorted = y[order]\n",
    "      w_sorted = w[order]\n",
    "      # cumulative stats to evaluate splits between unique values\n",
    "      wl = 0.0; wr = np.sum(w_sorted)\n",
    "      yl = 0.0; yr = np.sum(w_sorted*(y_sorted==1))\n",
    "      for i in range(0, n-1):\n",
    "        wi = w_sorted[i]\n",
    "        yi = 1.0 if y_sorted[i]==1 else 0.0\n",
    "        wl += wi; wr -= wi\n",
    "        yl += wi*yi; yr -= wi*yi\n",
    "        if wl < self.min_samples_leaf or wr < self.min_samples_leaf:\n",
    "          continue\n",
    "        if x_sorted[i] == x_sorted[i+1]:\n",
    "          continue\n",
    "        p1_l = yl / wl if wl>0 else 0.0\n",
    "        p1_r = yr / wr if wr>0 else 0.0\n",
    "        gini_l = 1 - p1_l**2 - (1-p1_l)**2\n",
    "        gini_r = 1 - p1_r**2 - (1-p1_r)**2\n",
    "        imp = (wl/(wl+wr))*gini_l + (wr/(wl+wr))*gini_r\n",
    "        gain = base_imp - imp\n",
    "        if (best is None) or (gain > best[\"gain\"]):\n",
    "          thr = 0.5*(x_sorted[i] + x_sorted[i+1])\n",
    "          best = {\"feat\": j, \"thr\": thr, \"gain\": gain}\n",
    "    return best\n",
    "\n",
    "  def _build(self, X, y, w, depth, rng):\n",
    "    n, d = X.shape\n",
    "    num_pos = np.sum(w*(y==1))\n",
    "    num_neg = np.sum(w*(y==0))\n",
    "    prob = (num_pos/(num_pos+num_neg+1e-12))\n",
    "    node = {\"prob\": float(prob), \"depth\": depth}\n",
    "    # stopping criteria\n",
    "    if (self.max_depth is not None and depth >= self.max_depth) or n < self.min_samples_split or prob in (0.0,1.0):\n",
    "      return node\n",
    "    # feature subsampling\n",
    "    mtry = self.mtry if self.mtry is not None else int(np.sqrt(d))\n",
    "    feat_idxs = rng.choice(d, size=max(1, mtry), replace=False)\n",
    "    split = self.best_split(X, y, w, feat_idxs)\n",
    "    if split is None or split[\"gain\"] <= 1e-12:\n",
    "      return node\n",
    "    j, thr = split[\"feat\"], split[\"thr\"]\n",
    "    left_mask = X[:, j] <= thr\n",
    "    right_mask = ~left_mask\n",
    "    if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "      return node\n",
    "    node.update({\"feat\": int(j), \"thr\": float(thr)})\n",
    "    node[\"left\"] = self._build(X[left_mask], y[left_mask], w[left_mask], depth+1, rng)\n",
    "    node[\"right\"] = self._build(X[right_mask], y[right_mask], w[right_mask], depth+1, rng)\n",
    "    return node\n",
    "\n",
    "  def fit(self, X, y, sample_weight=None):\n",
    "    rng = np.random.default_rng(self.random_state)\n",
    "    if sample_weight is None:\n",
    "      sample_weight = np.ones(len(y), dtype=float)\n",
    "    self.tree_ = self._build(np.asarray(X), np.asarray(y).astype(int), np.asarray(sample_weight, float), 0, rng)\n",
    "    return self\n",
    "\n",
    "  def _predict_row(self, row, node):\n",
    "    while True:\n",
    "      if \"feat\" not in node:\n",
    "        return node[\"prob\"]\n",
    "      if row[node[\"feat\"]] <= node[\"thr\"]:\n",
    "        node = node[\"left\"]\n",
    "      else:\n",
    "        node = node[\"right\"]\n",
    "\n",
    "  def predict_proba(self, X):\n",
    "    X = np.asarray(X)\n",
    "    return np.array([self._predict_row(x, self.tree_) for x in X])\n",
    "\n",
    "class RandomForestScratch:\n",
    "  def __init__(self, n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1, mtry=None, random_state=42, bootstrap=True, class_weight=\"balanced\"):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_depth = max_depth\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.mtry = mtry\n",
    "    self.random_state = random_state\n",
    "    self.bootstrap = bootstrap\n",
    "    self.class_weight = class_weight\n",
    "    self.trees = []\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    rng = np.random.default_rng(self.random_state)\n",
    "    n = len(y)\n",
    "    # class weights\n",
    "    if self.class_weight==\"balanced\":\n",
    "      n_pos = np.sum(y==1); n_neg = np.sum(y==0)\n",
    "      w_pos = n/(2*max(n_pos,1)); w_neg = n/(2*max(n_neg,1))\n",
    "      base_w = np.where(y==1, w_pos, w_neg).astype(float)\n",
    "    else:\n",
    "      base_w = np.ones(n, dtype=float)\n",
    "\n",
    "    self.trees = []\n",
    "    for t in range(self.n_estimators):\n",
    "      if self.bootstrap:\n",
    "        idx = rng.choice(n, size=n, replace=True)\n",
    "      else:\n",
    "        idx = np.arange(n)\n",
    "      tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf, mtry=self.mtry, random_state=int(rng.integers(1, 1e9)))\n",
    "      tree.fit(X[idx], y[idx], sample_weight=base_w[idx])\n",
    "      self.trees.append(tree)\n",
    "    return self\n",
    "\n",
    "  def predict_proba(self, X):\n",
    "    probs = np.mean([tr.predict_proba(X) for tr in self.trees], axis=0)\n",
    "    return np.clip(probs, 1e-6, 1-1e-6)\n",
    "\n",
    "# Train RF from scratch\n",
    "rf = RandomForestScratch(n_estimators=200, max_depth=None, min_samples_split=4, min_samples_leaf=2, mtry=None, random_state=RANDOM_STATE, bootstrap=True, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "rf_val_prob = rf.predict_proba(X_val)\n",
    "rf_test_prob = rf.predict_proba(X_test)\n",
    "print(\"RF (scratch) — Val Metrics\")\n",
    "print(evaluate_(y_val, rf_val_prob, prefix=\"RF/Val/\"))\n",
    "print(\"\\nRF (scratch) — Test Metrics\")\n",
    "print(evaluate_(y_test, rf_test_prob, prefix=\"RF/Test/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEsaPg1VnQnI",
    "outputId": "1c005fc6-8063-4150-f180-1bc948369096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN — Val Metrics\n",
      "{'DNN/Val/Accuracy': 0.7431930693069307, 'DNN/Val/Precision': 0.7492767598842812, 'DNN/Val/Recall': 0.6818780166739795, 'DNN/Val/F1': 0.7139903514812375, 'DNN/Val/ROC_AUC': 0.8097803817788377, 'DNN/Val/PR_AUC(AP)': 0.7795127058794199, 'DNN/Val/ConfusionMatrix': [[2049, 520], [725, 1554]]}\n",
      "\n",
      "DNN — Test Metrics\n",
      "{'DNN/Test/Accuracy': 0.7431176573733123, 'DNN/Test/Precision': 0.7563237774030351, 'DNN/Test/Recall': 0.6691533010070867, 'DNN/Test/F1': 0.7100732238269308, 'DNN/Test/ROC_AUC': 0.8006702557472942, 'DNN/Test/PR_AUC(AP)': 0.7782351008033003, 'DNN/Test/ConfusionMatrix': [[2444, 578], [887, 1794]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title DNN (from-scratch training loop in PyTorch)\n",
    "class DNN(nn.Module):\n",
    "  def __init__(self, in_dim):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(in_dim, 256)\n",
    "    self.bn1 = nn.BatchNorm1d(256)\n",
    "    self.fc2 = nn.Linear(256, 128)\n",
    "    self.bn2 = nn.BatchNorm1d(128)\n",
    "    self.fc3 = nn.Linear(128, 1)\n",
    "    self.drop = nn.Dropout(0.2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.drop(F.relu(self.bn1(self.fc1(x))))\n",
    "    x = self.drop(F.relu(self.bn2(self.fc2(x))))\n",
    "    return self.fc3(x).squeeze(1)\n",
    "\n",
    "def train_dnn(X_train, y_train, X_val, y_val, epochs=50, batch_size=512, lr=1e-3):\n",
    "  Xtr = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "  ytr = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "  Xv = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "  yv = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "  model = DNN(X_train.shape[1]).to(device)\n",
    "  pos = float(np.sum(y_train==1)); neg = float(np.sum(y_train==0))\n",
    "  pos_weight = torch.tensor([neg/max(pos,1.0)], dtype=torch.float32).to(device)\n",
    "  criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "  optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "  sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "  best_auc = -1; best = copy.deepcopy(model.state_dict())\n",
    "  patience = 8; no_improve = 0\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # mini-batches\n",
    "    idx = torch.randperm(Xtr.size(0))\n",
    "    for i in range(0, Xtr.size(0), batch_size):\n",
    "      b = idx[i:i+batch_size]\n",
    "      xb, yb = Xtr[b], ytr[b]\n",
    "      optim.zero_grad()\n",
    "      logits = model(xb)\n",
    "      loss = criterion(logits, yb)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "      optim.step()\n",
    "    # validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_prob = torch.sigmoid(model(Xv)).cpu().numpy()\n",
    "      auc = roc_auc_score_(y_val, val_prob)\n",
    "    sched.step(auc)\n",
    "    if auc > best_auc + 1e-4:\n",
    "      best_auc = auc; best = copy.deepcopy(model.state_dict()); no_improve = 0\n",
    "    else:\n",
    "      no_improve += 1\n",
    "      if no_improve >= patience: break\n",
    "\n",
    "  model.load_state_dict(best)\n",
    "  with torch.no_grad():\n",
    "    val_prob = torch.sigmoid(model(Xv)).cpu().numpy()\n",
    "  return model, val_prob\n",
    "\n",
    "dnn_model, dnn_val_prob = train_dnn(X_train, y_train, X_val, y_val, epochs=40, batch_size=512, lr=1e-3)\n",
    "with torch.no_grad():\n",
    "  dnn_test_prob = torch.sigmoid(dnn_model(torch.tensor(X_test, dtype=torch.float32).to(device))).cpu().numpy()\n",
    "print(\"DNN — Val Metrics\")\n",
    "print(evaluate_(y_val, dnn_val_prob, prefix=\"DNN/Val/\"))\n",
    "print(\"\\nDNN — Test Metrics\")\n",
    "print(evaluate_(y_test, dnn_test_prob, prefix=\"DNN/Test/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4yoMQ8Jnn-r",
    "outputId": "3c68aed3-d21b-45b7-c843-961f59e6053b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBN — Val Metrics\n",
      "{'DBN/Val/Accuracy': 0.7436056105610561, 'DBN/Val/Precision': 0.7648261758691203, 'DBN/Val/Recall': 0.656428258007898, 'DBN/Val/F1': 0.706493506493009, 'DBN/Val/ROC_AUC': 0.8094971075627263, 'DBN/Val/PR_AUC(AP)': 0.7809143786514124, 'DBN/Val/ConfusionMatrix': [[2109, 460], [783, 1496]]}\n",
      "\n",
      "DBN — Test Metrics\n",
      "{'DBN/Test/Accuracy': 0.7385586533403472, 'DBN/Test/Precision': 0.7665770609318994, 'DBN/Test/Recall': 0.6381947034688547, 'DBN/Test/F1': 0.6965194382246209, 'DBN/Test/ROC_AUC': 0.7990852114951598, 'DBN/Test/PR_AUC(AP)': 0.7768939730556379, 'DBN/Test/ConfusionMatrix': [[2501, 521], [970, 1711]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title DBN — Stacked RBMs (from scratch in PyTorch) + fine-tune\n",
    "class RBM(nn.Module):\n",
    "  def __init__(self, n_visible, n_hidden, k=1, lr=1e-3, momentum=0.5, weight_decay=1e-4):\n",
    "    super().__init__()\n",
    "    self.W = nn.Parameter(torch.randn(n_visible, n_hidden) * 0.01)\n",
    "    self.vb = nn.Parameter(torch.zeros(n_visible))\n",
    "    self.hb = nn.Parameter(torch.zeros(n_hidden))\n",
    "    self.k = k; self.lr = lr; self.momentum = momentum; self.weight_decay = weight_decay\n",
    "    # velocity for momentum\n",
    "    self.W_m = torch.zeros_like(self.W)\n",
    "    self.vb_m = torch.zeros_like(self.vb)\n",
    "    self.hb_m = torch.zeros_like(self.hb)\n",
    "\n",
    "  def sample_h(self, v):\n",
    "    p = torch.sigmoid(v @ self.W + self.hb)\n",
    "    return p, torch.bernoulli(p)\n",
    "\n",
    "  def sample_v(self, h):\n",
    "    p = torch.sigmoid(h @ self.W.t() + self.vb)\n",
    "    return p, torch.bernoulli(p)\n",
    "\n",
    "  def contrastive_divergence(self, v0):\n",
    "    ph0, h0 = self.sample_h(v0)\n",
    "    vk = v0; hk = h0\n",
    "    for _ in range(self.k):\n",
    "      pvk, vk = self.sample_v(hk)\n",
    "      phk, hk = self.sample_h(vk)\n",
    "    positive_grad = v0.t() @ ph0\n",
    "    negative_grad = vk.t() @ phk\n",
    "    dW = (positive_grad - negative_grad) / v0.size(0) - self.weight_decay * self.W\n",
    "    dvb = torch.mean(v0 - vk, dim=0)\n",
    "    dhb = torch.mean(ph0 - phk, dim=0)\n",
    "\n",
    "    self.W_m = self.momentum * self.W_m + self.lr * dW\n",
    "    self.vb_m = self.momentum * self.vb_m + self.lr * dvb\n",
    "    self.hb_m = self.momentum * self.hb_m + self.lr * dhb\n",
    "\n",
    "    self.W.data += self.W_m\n",
    "    self.vb.data += self.vb_m\n",
    "    self.hb.data += self.hb_m\n",
    "\n",
    "  def forward_hidden(self, v):\n",
    "    return torch.sigmoid(v @ self.W + self.hb)\n",
    "\n",
    "def pretrain_dbn(X, layer_sizes=[256, 128], epochs=10, batch_size=256, k=1):\n",
    "  data = torch.tensor(X, dtype=torch.float32)\n",
    "  rbms = []\n",
    "  vis = X.shape[1]\n",
    "  for h in layer_sizes:\n",
    "    rbm = RBM(vis, h, k=k, lr=1e-3, momentum=0.5, weight_decay=1e-4)\n",
    "    rbm.train()\n",
    "    for epoch in range(epochs):\n",
    "      perm = torch.randperm(data.size(0))\n",
    "      for i in range(0, data.size(0), batch_size):\n",
    "        batch_idx = perm[i:i+batch_size]\n",
    "        v0 = data[batch_idx]\n",
    "        rbm.contrastive_divergence(v0)\n",
    "    with torch.no_grad():\n",
    "      data = rbm.forward_hidden(data)\n",
    "    rbms.append(rbm); vis = h\n",
    "  return rbms\n",
    "\n",
    "class DBNClassifier(nn.Module):\n",
    "  def __init__(self, input_dim, layer_sizes=[256,128]):\n",
    "    super().__init__()\n",
    "    layers = []; last = input_dim\n",
    "    for h in layer_sizes:\n",
    "      layers += [nn.Linear(last, h), nn.ReLU()]\n",
    "      last = h\n",
    "    self.feat = nn.Sequential(*layers)\n",
    "    self.head = nn.Linear(last, 1)\n",
    "  def forward(self, x):\n",
    "    return self.head(self.feat(x)).squeeze(1)\n",
    "\n",
    "def init_from_rbms(model, rbms):\n",
    "  lin_layers = [m for m in model.feat if isinstance(m, nn.Linear)]\n",
    "  for lin, rbm in zip(lin_layers, rbms):\n",
    "    with torch.no_grad():\n",
    "      lin.weight.copy_(rbm.W.t())\n",
    "      lin.bias.copy_(rbm.hb)\n",
    "\n",
    "# Pretrain + fine-tune\n",
    "rbm_layers = [256, 128]\n",
    "rbms = pretrain_dbn(X_train, layer_sizes=rbm_layers, epochs=8, batch_size=256, k=1)\n",
    "dbn = DBNClassifier(X_train.shape[1], layer_sizes=rbm_layers).to(device)\n",
    "init_from_rbms(dbn, rbms)\n",
    "\n",
    "pos = float(np.sum(y_train==1)); neg = float(np.sum(y_train==0))\n",
    "pos_weight = torch.tensor([neg/max(pos,1.0)], dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optim = torch.optim.AdamW(dbn.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "best_auc = -1; best = copy.deepcopy(dbn.state_dict())\n",
    "patience = 8; no_improve = 0\n",
    "\n",
    "Xtr_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "ytr_t = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "Xv_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "\n",
    "for epoch in range(40):\n",
    "  dbn.train()\n",
    "  idx = torch.randperm(Xtr_t.size(0))\n",
    "  for i in range(0, Xtr_t.size(0), 512):\n",
    "    b = idx[i:i+512]\n",
    "    xb = Xtr_t[b]; yb = ytr_t[b]\n",
    "    optim.zero_grad()\n",
    "    logits = dbn(xb)\n",
    "    loss = criterion(logits, yb)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(dbn.parameters(), 3.0)\n",
    "    optim.step()\n",
    "  dbn.eval()\n",
    "  with torch.no_grad():\n",
    "    val_prob = torch.sigmoid(dbn(Xv_t)).cpu().numpy()\n",
    "    auc = roc_auc_score_(y_val, val_prob)\n",
    "  sched.step(auc)\n",
    "  if auc > best_auc + 1e-4:\n",
    "    best_auc = auc; best = copy.deepcopy(dbn.state_dict()); no_improve = 0\n",
    "  else:\n",
    "    no_improve += 1\n",
    "    if no_improve >= patience: break\n",
    "\n",
    "dbn.load_state_dict(best)\n",
    "with torch.no_grad():\n",
    "  dbn_val_prob = torch.sigmoid(dbn(Xv_t)).cpu().numpy()\n",
    "  dbn_test_prob = torch.sigmoid(dbn(torch.tensor(X_test, dtype=torch.float32).to(device))).cpu().numpy()\n",
    "\n",
    "print(\"DBN — Val Metrics\")\n",
    "print(evaluate_(y_val, dbn_val_prob, prefix=\"DBN/Val/\"))\n",
    "print(\"\\nDBN — Test Metrics\")\n",
    "print(evaluate_(y_test, dbn_test_prob, prefix=\"DBN/Test/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAq13zLTn_43",
    "outputId": "c1a0a35c-211e-4ad3-aa29-7948106ae69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet-like — Val Metrics\n",
      "{'TabNet/Val/Accuracy': 0.7341171617161716, 'TabNet/Val/Precision': 0.7915194346289749, 'TabNet/Val/Recall': 0.5897323387450634, 'TabNet/Val/F1': 0.6758863464918412, 'TabNet/Val/ROC_AUC': 0.7990973484611049, 'TabNet/Val/PR_AUC(AP)': 0.7631814274704951, 'TabNet/Val/ConfusionMatrix': [[2215, 354], [935, 1344]]}\n",
      "\n",
      "TabNet-like — Test Metrics\n",
      "{'TabNet/Test/Accuracy': 0.7271611432579345, 'TabNet/Test/Precision': 0.7937336814621406, 'TabNet/Test/Recall': 0.5669526296158148, 'TabNet/Test/F1': 0.6614447345512977, 'TabNet/Test/ROC_AUC': 0.7881598601428614, 'TabNet/Test/PR_AUC(AP)': 0.7669052891624447, 'TabNet/Test/ConfusionMatrix': [[2627, 395], [1161, 1520]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title TabNet-like (from scratch in PyTorch; simplified)\n",
    "class GhostBN(nn.Module):\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    super().__init__()\n",
    "    self.bn = nn.BatchNorm1d(dim, eps=eps, momentum=momentum)\n",
    "  def forward(self, x):\n",
    "    return self.bn(x)\n",
    "\n",
    "class GLU(nn.Module):\n",
    "  def __init__(self, dim):\n",
    "    super().__init__()\n",
    "    self.fc = nn.Linear(dim, dim*2)\n",
    "    self.bn = GhostBN(dim*2)\n",
    "  def forward(self, x):\n",
    "    x = self.bn(self.fc(x))\n",
    "    a, b = x.chunk(2, dim=1)\n",
    "    return a * torch.sigmoid(b)\n",
    "\n",
    "class FeatureTransformer(nn.Module):\n",
    "  def __init__(self, dim, n_glu=2):\n",
    "    super().__init__()\n",
    "    self.layers = nn.ModuleList([GLU(dim) for _ in range(n_glu)])\n",
    "    self.rescale = nn.Parameter(torch.ones(1, dim))\n",
    "  def forward(self, x):\n",
    "    for glu in self.layers:\n",
    "      x = (x + glu(x)) * math.sqrt(0.5)\n",
    "    return x * self.rescale\n",
    "\n",
    "class AttentiveTransformer(nn.Module):\n",
    "  def __init__(self, in_dim, out_dim):\n",
    "    super().__init__()\n",
    "    self.fc = nn.Linear(in_dim, out_dim)\n",
    "    self.bn = GhostBN(out_dim)\n",
    "  def forward(self, x, prior):\n",
    "    x = self.bn(self.fc(x))\n",
    "    x = x * prior\n",
    "    return F.softmax(x, dim=1)\n",
    "\n",
    "class TabNetLike(nn.Module):\n",
    "  def __init__(self, input_dim, decision_dim=64, n_steps=3, relaxation=1.5):\n",
    "    super().__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.decision_dim = decision_dim\n",
    "    self.n_steps = n_steps\n",
    "    self.relax = relaxation\n",
    "    self.shared = FeatureTransformer(input_dim, n_glu=2)\n",
    "    self.step_ft = nn.ModuleList([FeatureTransformer(decision_dim, n_glu=2) for _ in range(n_steps)])\n",
    "    self.att = nn.ModuleList([AttentiveTransformer(decision_dim, input_dim) for _ in range(n_steps)])\n",
    "    self.fc_in = nn.Linear(input_dim, decision_dim)\n",
    "    self.bn_in = GhostBN(decision_dim)\n",
    "    self.head = nn.Linear(decision_dim, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    prior = torch.ones(x.size(0), self.input_dim, device=x.device)\n",
    "    features = self.shared(x)\n",
    "    h = F.relu(self.bn_in(self.fc_in(features)))\n",
    "    out_agg = 0\n",
    "    for s in range(self.n_steps):\n",
    "      mask = self.att[s](h, prior)\n",
    "      x_masked = x * mask\n",
    "      h = self.step_ft[s](F.relu(self.bn_in(self.fc_in(x_masked))))\n",
    "      out_agg = out_agg + h\n",
    "      prior = prior * (self.relax - mask)\n",
    "    logits = self.head(out_agg)\n",
    "    return logits.squeeze(1)\n",
    "\n",
    "def train_tabnet(X_train, y_train, X_val, y_val, epochs=50, batch_size=512, lr=1e-3):\n",
    "  model = TabNetLike(input_dim=X_train.shape[1], decision_dim=64, n_steps=3, relaxation=1.5).to(device)\n",
    "  pos = float(np.sum(y_train==1)); neg = float(np.sum(y_train==0))\n",
    "  pos_weight = torch.tensor([neg/max(pos,1.0)], dtype=torch.float32).to(device)\n",
    "  criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "  optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "  sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "  Xtr = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "  ytr = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "  Xv = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "\n",
    "  best_auc = -1; best = copy.deepcopy(model.state_dict())\n",
    "  patience = 8; no_improve = 0\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    idx = torch.randperm(Xtr.size(0))\n",
    "    for i in range(0, Xtr.size(0), batch_size):\n",
    "      b = idx[i:i+batch_size]\n",
    "      xb = Xtr[b]; yb = ytr[b]\n",
    "      optim.zero_grad()\n",
    "      logits = model(xb)\n",
    "      loss = criterion(logits, yb)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "      optim.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_prob = torch.sigmoid(model(Xv)).cpu().numpy()\n",
    "      auc = roc_auc_score_(y_val, val_prob)\n",
    "    sched.step(auc)\n",
    "    if auc > best_auc + 1e-4:\n",
    "      best_auc = auc; best = copy.deepcopy(model.state_dict()); no_improve = 0\n",
    "    else:\n",
    "      no_improve += 1\n",
    "      if no_improve >= patience: break\n",
    "\n",
    "  model.load_state_dict(best)\n",
    "  with torch.no_grad():\n",
    "    val_prob = torch.sigmoid(model(Xv)).cpu().numpy()\n",
    "  return model, val_prob\n",
    "\n",
    "tab_model, tab_val_prob = train_tabnet(X_train, y_train, X_val, y_val, epochs=50, batch_size=512, lr=1e-3)\n",
    "with torch.no_grad():\n",
    "  tab_test_prob = torch.sigmoid(tab_model(torch.tensor(X_test, dtype=torch.float32).to(device))).cpu().numpy()\n",
    "print(\"TabNet-like — Val Metrics\")\n",
    "print(evaluate_(y_val, tab_val_prob, prefix=\"TabNet/Val/\"))\n",
    "print(\"\\nTabNet-like — Test Metrics\")\n",
    "print(evaluate_(y_test, tab_test_prob, prefix=\"TabNet/Test/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "AbLjDXf_oTGX",
    "outputId": "adb3e052-5be1-4886-9168-9741af1866d3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DNN\",\n          \"TabNet\",\n          \"RandomForest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007342942914913584,\n        \"min\": 0.7271611432579345,\n        \"max\": 0.7431176573733123,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7431176573733123,\n          0.7271611432579345,\n          0.7422409258285113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01595370592448314,\n        \"min\": 0.7563237774030351,\n        \"max\": 0.7937336814621406,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7563237774030351,\n          0.7937336814621406,\n          0.7675651789659741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04432473665567979,\n        \"min\": 0.5669526296158148,\n        \"max\": 0.6691533010070867,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6691533010070867,\n          0.5669526296158148,\n          0.6478925773964936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021546116807856473,\n        \"min\": 0.6614447345512977,\n        \"max\": 0.7100732238269308,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7100732238269308,\n          0.6614447345512977,\n          0.7026699029121246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC_AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005999660783747303,\n        \"min\": 0.7881598601428614,\n        \"max\": 0.8006702557472942,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8006702557472942,\n          0.7881598601428614,\n          0.800472526352192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PR_AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005277345947029705,\n        \"min\": 0.7669052891624447,\n        \"max\": 0.7782351008033003,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7782351008033003,\n          0.7669052891624447,\n          0.7770458029493591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d55d6cbf-618e-439e-a427-a59f8ddab1f7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.742241</td>\n",
       "      <td>0.767565</td>\n",
       "      <td>0.647893</td>\n",
       "      <td>0.702670</td>\n",
       "      <td>0.800473</td>\n",
       "      <td>0.777046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNN</td>\n",
       "      <td>0.743118</td>\n",
       "      <td>0.756324</td>\n",
       "      <td>0.669153</td>\n",
       "      <td>0.710073</td>\n",
       "      <td>0.800670</td>\n",
       "      <td>0.778235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBN</td>\n",
       "      <td>0.738559</td>\n",
       "      <td>0.766577</td>\n",
       "      <td>0.638195</td>\n",
       "      <td>0.696519</td>\n",
       "      <td>0.799085</td>\n",
       "      <td>0.776894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.727161</td>\n",
       "      <td>0.793734</td>\n",
       "      <td>0.566953</td>\n",
       "      <td>0.661445</td>\n",
       "      <td>0.788160</td>\n",
       "      <td>0.766905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d55d6cbf-618e-439e-a427-a59f8ddab1f7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d55d6cbf-618e-439e-a427-a59f8ddab1f7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d55d6cbf-618e-439e-a427-a59f8ddab1f7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e62c825f-5d5f-4c58-bee2-82ab01324945\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e62c825f-5d5f-4c58-bee2-82ab01324945')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e62c825f-5d5f-4c58-bee2-82ab01324945 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          Model  Accuracy  Precision    Recall        F1   ROC_AUC    PR_AUC\n",
       "0  RandomForest  0.742241   0.767565  0.647893  0.702670  0.800473  0.777046\n",
       "1           DNN  0.743118   0.756324  0.669153  0.710073  0.800670  0.778235\n",
       "2           DBN  0.738559   0.766577  0.638195  0.696519  0.799085  0.776894\n",
       "3        TabNet  0.727161   0.793734  0.566953  0.661445  0.788160  0.766905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#@title Final comparison table (all from-scratch models)\n",
    "def summarize(name, y_true, y_prob):\n",
    "  m = evaluate_(y_true, y_prob)\n",
    "  line = {\n",
    "      \"Model\": name,\n",
    "      \"Accuracy\": m[\"Accuracy\"],\n",
    "      \"Precision\": m[\"Precision\"],\n",
    "      \"Recall\": m[\"Recall\"],\n",
    "      \"F1\": m[\"F1\"],\n",
    "      \"ROC_AUC\": m[\"ROC_AUC\"],\n",
    "      \"PR_AUC\": m[\"PR_AUC(AP)\"],\n",
    "  }\n",
    "  return line\n",
    "\n",
    "summary = []\n",
    "summary.append(summarize(\"RandomForest\", y_test, rf_test_prob))\n",
    "summary.append(summarize(\"DNN\", y_test, dnn_test_prob))\n",
    "summary.append(summarize(\"DBN\", y_test, dbn_test_prob))\n",
    "summary.append(summarize(\"TabNet\", y_test, tab_test_prob))\n",
    "\n",
    "pd.DataFrame(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_auc_roc(y_true, y_prob):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color=\"white\", lw=2, linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
